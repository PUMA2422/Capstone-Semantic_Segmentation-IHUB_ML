{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6cad87-96f9-4ffc-91a1-7dfd4506840e",
   "metadata": {},
   "source": [
    "# Setup for the model training and usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7824422-da59-41c2-be4e-2c55adfdf67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Setup base directories\n",
    "BASE_DIR = os.path.abspath(\"..\")\n",
    "DATA_DIRS = [\n",
    "    os.path.join(BASE_DIR, \"data/IDD_Segmentation/IDD_Segmentation\"),\n",
    "    os.path.join(BASE_DIR, \"data/IDD_Segmentation/idd20kII\")\n",
    "]\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "UTILS_DIR = os.path.join(BASE_DIR, \"utils\")\n",
    "\n",
    "# Add directories to path\n",
    "sys.path.append(MODELS_DIR)\n",
    "sys.path.append(UTILS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47afb71-d6d4-40f9-8d46-3ede76679315",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f29a89-6768-4554-a8f9-28178caba5be",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from attention_unet import attention_unet\n",
    "from data_generator import IDDSegmentationGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"attention_unet_model.h5\")\n",
    "\n",
    "\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "for data_root in DATA_DIRS:\n",
    "    img_root = os.path.join(data_root, \"leftImg8bit/train\")\n",
    "    mask_root = os.path.join(data_root, \"gtFine/train\")\n",
    "\n",
    "    cities = os.listdir(img_root)\n",
    "    for city in tqdm(cities, desc=f\"Processing {data_root}\"):\n",
    "        img_dir = os.path.join(img_root, city)\n",
    "        msk_dir = os.path.join(mask_root, city)\n",
    "\n",
    "        img_files = glob.glob(os.path.join(img_dir, \"*_leftImg8bit.png\"))\n",
    "        for img_path in img_files:\n",
    "            base = os.path.basename(img_path).replace(\"_leftImg8bit.png\", \"\")\n",
    "            mask_path = os.path.join(msk_dir, base + \"_gtFine_labelLevel3Ids.png\")\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                image_paths.append(img_path)\n",
    "                mask_paths.append(mask_path)\n",
    "\n",
    "train_img, val_img, train_mask, val_mask = train_test_split(\n",
    "    image_paths, mask_paths, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_gen = IDDSegmentationGenerator(train_img, train_mask, batch_size=8)\n",
    "val_gen = IDDSegmentationGenerator(val_img, val_mask, batch_size=8)\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"Found existing model. Loading...\")\n",
    "    model = load_model(MODEL_PATH, compile=False)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Model load complete\")\n",
    "else:\n",
    "    print(\"No saved model found. Training the model...\")\n",
    "    model = attention_unet(input_shape=(256, 256, 3), num_classes=27)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=20)\n",
    "    model.save(MODEL_PATH)\n",
    "    print(\"Model saved to disk at\",MODEL_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af7bd2d-e65d-4ca9-8712-0b91cb7277d0",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f6fce-956f-4ed1-8fd0-62d615b49228",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_gen)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd519d-5483-4280-937a-bdb401e10f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images, sample_masks = val_gen[0]\n",
    "preds = model.predict(sample_images)\n",
    "pred_labels = np.argmax(preds, axis=-1)\n",
    "true_labels = np.argmax(sample_masks, axis=-1)\n",
    "\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.subplot(1, 3, 1); plt.imshow(sample_images[i]); plt.title(\"Input\")\n",
    "    plt.subplot(1, 3, 2); plt.imshow(true_labels[i]); plt.title(\"Ground Truth\")\n",
    "    plt.subplot(1, 3, 3); plt.imshow(pred_labels[i]); plt.title(\"Prediction\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d572a9b-5eb9-4ad2-a77d-c5067d2aa427",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Capstone)",
   "language": "python",
   "name": "capstone-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
